{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036880fd-a267-4289-8e64-e7cb654e3d69",
   "metadata": {},
   "source": [
    "# Start with loading the model and processing a text As Doccument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec57f5c-4ff3-48df-87f5-48a7d4b8738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # basic english model \n",
    "\n",
    "# Process a text to create a Doc object\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad47982-a974-4ae8-9427-5ce29afb136b",
   "metadata": {},
   "source": [
    "# Different Compoments of Doccument \n",
    "\n",
    "#### 1   token.text: The original word text.\n",
    "#### 2   token.lemma_: The base form of the word.\n",
    "#### 3   token.pos_: Part of Speech (POS) tag.\n",
    "#### 4   token.dep_: Syntactic dependency. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042abfd-6e67-46a6-946d-3133b992b223",
   "metadata": {},
   "source": [
    "### 1 POS (Part Of Speach )\n",
    "\n",
    "##### Part-of-Speech (POS) refers to the grammatical categories or word classes that classify words based on their syntactic roles and functions in a \n",
    "\n",
    "##### sentence. In Natural Language Processing (NLP), POS tagging is the process of assigning these grammatical categories to each word in a text.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c77c6a-26f9-4736-9fa7-272149a4eff9",
   "metadata": {},
   "source": [
    "ADJ (Adjective): Describes a noun, providing more information about it.\n",
    "\n",
    "Example: \"beautiful\", \"quick\"\n",
    "\n",
    "ADP (Adposition): Relates a noun to another word, often indicating direction, place, or time (includes prepositions and postpositions).\n",
    "Example: \"in\", \"on\", \"by\"\n",
    "\n",
    "\n",
    "ADV (Adverb): Modifies a verb, adjective, or another adverb, often describing how, when, or where something happens.\n",
    "Example: \"quickly\", \"very\"\n",
    "\n",
    "\n",
    "AUX (Auxiliary Verb): Helps the main verb by expressing tense, mood, or voice.\n",
    "Example: \"is\", \"have\", \"will\"\n",
    "\n",
    "CCONJ (Coordinating Conjunction): Connects words, phrases, or clauses that are of equal syntactic importance.\n",
    "Example: \"and\", \"but\", \"or\"\n",
    "    \n",
    "DET (Determiner): Introduces a noun, specifying its definiteness, quantity, or possession.\n",
    "Example: \"the\", \"a\", \"some\"\n",
    "\n",
    "INTJ (Interjection): Expresses emotion or a reaction, often standing alone.\n",
    "Example: \"wow\", \"ouch\"\n",
    "    \n",
    "NOUN (Noun): Refers to a person, place, thing, or idea.\n",
    "Example: \"dog\", \"computer\"\n",
    "\n",
    "NUM (Numeral): Represents a number or numerical value.\n",
    "Example: \"one\", \"two\", \"3\"\n",
    "\n",
    "PART (Particle): A small function word that has a grammatical role but doesnâ€™t belong to the main word classes (e.g., adverbial particles in phrasal verbs).\n",
    "Example: \"not\", \"to\" (as in \"to go\")\n",
    "\n",
    "PRON (Pronoun): Replaces a noun in a sentence.\n",
    "Example: \"he\", \"she\", \"they\"\n",
    "\n",
    "PROPN (Proper Noun): Refers to specific names of people, places, organizations, etc., usually capitalized.\n",
    "Example: \"John\", \"London\", \"Microsoft\"\n",
    "    \n",
    "PUNCT (Punctuation): Any punctuation mark that contributes to the structure and meaning of a text.\n",
    "Example: \".\", \",\", \"?\"\n",
    "    \n",
    "SCONJ (Subordinating Conjunction): Connects a subordinate clause to a main clause, often introducing a dependent idea.\n",
    "Example: \"because\", \"although\", \"if\"\n",
    "\n",
    "SYM (Symbol): Non-alphabetic characters that represent concepts, often mathematical or currency symbols.\n",
    "Example: \"$\", \"%\", \"+\"\n",
    "\n",
    "VERB (Verb): Describes an action, state, or occurrence.\n",
    "Example: \"run\", \"is\", \"write\"\n",
    "\n",
    "X (Other): Used for words that do not fit into any other category, often foreign words, typos, or placeholders.\n",
    "Example: \"hmm\", \"grr\", \"xxx\"\n",
    "\n",
    "SPACE (Space): Represents a space between words, often included for formatting purposes in tokenization.\n",
    "Example: \" \" (a blank space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc64682-b3c9-4fd0-8470-d7b82430b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "AUX\n",
      "VERB\n",
      "ADP\n",
      "VERB\n",
      "PROPN\n",
      "NOUN\n",
      "ADP\n",
      "SYM\n",
      "NUM\n",
      "NUM\n",
      "PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de5793-7aad-4993-93c0-c3ffed0bbfd8",
   "metadata": {},
   "source": [
    "### 2 Lemitization (Convert into root word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af740df-fe8d-447b-83f1-3da4f7756fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "be\n",
      "look\n",
      "at\n",
      "buy\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704e370-31df-41f1-ad97-6146b2800b22",
   "metadata": {},
   "source": [
    "### 3 Explanation of token.dep_\n",
    "#### dep_: This attribute returns the syntactic dependency label of a token as a string. It describes the role of the token in relation to its head token (the word it is syntactically connected to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de71071b-d50a-4ea8-91f4-225b6d6bd53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj\n",
      "aux\n",
      "ROOT\n",
      "prep\n",
      "pcomp\n",
      "dobj\n",
      "dep\n",
      "prep\n",
      "quantmod\n",
      "compound\n",
      "pobj\n",
      "punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3b2fa-ecd0-4c82-a950-cbd02316a92e",
   "metadata": {},
   "source": [
    "### 4 Orignal Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62753058-515f-4e58-9bf5-1282dfaaa30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9b1f2-3edc-4ba3-b17f-01b95de9b699",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388745f-2956-48ed-87a9-81865e0c9945",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER) is a process in Natural Language Processing (NLP) that identifies and classifies key information (entities) in text into predefined categories such as names of people, organizations, locations, dates, and more. Here's a more detailed explanation with clear examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217a316-f008-4179-ba5a-6b855c412190",
   "metadata": {},
   "source": [
    "Common Entity Types in NER:\n",
    "\n",
    "0 PERSON: Names of people.\n",
    "\n",
    "1 ORG: Organizations such as companies, institutions, government agencies.\n",
    "\n",
    "2 GPE: Geopolitical entities like countries, cities, states.\n",
    "\n",
    "3 LOC: Non-GPE locations, like mountains, rivers, regions.\n",
    "\n",
    "4 DATE: Dates, including days, months, years.\n",
    "\n",
    "5 TIME: Times, such as \"2:00 PM\".\n",
    "\n",
    "6 MONEY: Monetary values.\n",
    "\n",
    "7 PERCENT: Percentage values.\n",
    "\n",
    "8 FAC: Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "9 PRODUCT: Objects, vehicles, foods, etc. (Not services.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16a6ae-9d61-40fa-b923-8a7fbda4263a",
   "metadata": {},
   "source": [
    "### Why NER is Important:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbab479-043c-42a2-b846-7163279f94f1",
   "metadata": {},
   "source": [
    "\n",
    "Information Extraction: Automatically extracting important information from large volumes of text.\n",
    "\n",
    "Data Structuring: Structuring unstructured data into a more usable format for further analysis.\n",
    "                                                                         \n",
    "Search Optimization: Enhancing search engines to retrieve information more accurately.\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792f135-23b6-4b79-8145-95356e374f6f",
   "metadata": {},
   "source": [
    "### Example 1 Basic NER on a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ceb4e18-f17c-44e1-8b89-58e5730c5288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"i work at Apple\")\n",
    "for ent in doc1.ents:\n",
    "    print(ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3b59c-28af-4710-8705-4f343a73ed6d",
   "metadata": {},
   "source": [
    "### Example 2 Basic NER on a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "080a6748-698a-4555-a0f4-ae5f0dcc43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "# Process a sentence\n",
    "doc3 = nlp(\"Apple is looking at buying U.K. startup for $1 billion.\")\n",
    "\n",
    "# Print the entities found in the sentence\n",
    "for ent in doc3.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e907e-e4ff-4f6d-a4e0-034595f0d1fd",
   "metadata": {},
   "source": [
    "### Example 3 NER with Detailed Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bbed2f4-7c96-4552-b83f-5db13653539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Elon Musk, Label: PERSON, Start: 0, End: 9\n",
      "Entity: June 28, 1971, Label: DATE, Start: 22, End: 35\n",
      "Entity: Pretoria, Label: GPE, Start: 40, End: 48\n",
      "Entity: South Africa, Label: GPE, Start: 50, End: 62\n"
     ]
    }
   ],
   "source": [
    "# Process another sentence\n",
    "doc = nlp(\"Elon Musk was born on June 28, 1971, in Pretoria, South Africa.\")\n",
    "\n",
    "# Print detailed information about the entities\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}, Start: {ent.start_char}, End: {ent.end_char}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f0c0a-5a0e-4acc-a656-54ac9a027a21",
   "metadata": {},
   "source": [
    "### Example 5: Visualizing Named Entities with displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77cc27de-a804-4b59-96a0-e8694dd66e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is headquartered in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Seattle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and was founded by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jeff Bezos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1994\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Custom text\n",
    "text = \"Amazon is headquartered in Seattle, Washington, and was founded by Jeff Bezos in 1994.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Render the named entities\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa30c5-a29e-4f5a-9fd1-4296bc595f6e",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d34ba90-7323-4f11-8e77-735d915a2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google plans to open a new office in Tokyo by April 2023.\n",
      "Tesla unveiled the new Model S Plaid at the Fremont factory.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"Google plans to open a new office in Tokyo by April 2023. Tesla unveiled the new Model S Plaid at the Fremont factory.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "051e9e4a-5e4a-408c-8d32-ccff92e02307",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,ent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(docs\u001b[38;5;241m.\u001b[39ments):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ent\u001b[38;5;241m.\u001b[39mlabel_\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMONEY\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(ent\u001b[38;5;241m.\u001b[39mtext,ent\u001b[38;5;241m.\u001b[39mtext[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "transactions = \"Tony gave  $ 2  to Peter, Bruce gave $ 500 to Steve\"\n",
    "docs = nlp(transactions)\n",
    "for i,ent in enumerate(docs.ents):\n",
    "    if ent.label_==\"MONEY\":\n",
    "        print(ent.text,ent.text[i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42944401-b719-4fe6-9822-f203142ea492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22e39fe5-5f95-4e51-87c9-1300da67fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 $\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e26f193-c03b-4379-8514-711ddb67cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monetary value: two $\n",
      "Monetary value: 500 â‚¬\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# The text containing transactions\n",
    "transactions = \"Tony gave  two $ to Peter, Bruce gave 500 â‚¬ to Steve\"\n",
    "\n",
    "# Process the text with the NLP model\n",
    "doc = nlp(transactions)\n",
    "\n",
    "# List of currency symbols\n",
    "currency_symbols = {\"$\", \"â‚¬\", \"Â£\", \"Â¥\"}\n",
    "\n",
    "# Extract monetary values\n",
    "for i, token in enumerate(doc):\n",
    "    # Check if the token is a currency symbol\n",
    "    if token.text in currency_symbols:\n",
    "        # Look for the next token and previous token to find the amount\n",
    "        if i + 1 < len(doc):\n",
    "            next_token = doc[i + 1]\n",
    "            if next_token.like_num or next_token.pos_ == \"NUM\":\n",
    "                print(f\"Monetary value: {token.text} {next_token.text}\")\n",
    "        if i - 1 >= 0:\n",
    "            prev_token = doc[i - 1]\n",
    "            if prev_token.like_num or prev_token.pos_ == \"NUM\":\n",
    "                print(f\"Monetary value: {prev_token.text} {token.text}\")\n",
    "\n",
    "# Also print entities labeled as MONEY\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"MONEY\":\n",
    "        print(f\"Monetary value: {ent.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d32f3-b36b-4b64-9da0-7d6d152308ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
